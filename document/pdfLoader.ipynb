{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a300ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader,PyPDFLoader\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a50e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 document(s) from D:\\New folder (2)\\DS\\RAG\\ZuGraFix\\data\\text_files\\aboutme.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = r\"D:\\New folder (2)\\DS\\RAG\\ZuGraFix\\data\\text_files\\aboutme.pdf\"\n",
    "\n",
    "# Load the single PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s) from {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a6c187e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_document(document, chunk_size=1000, chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    return text_splitter.split_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d8c461c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks from all pages: 5\n"
     ]
    }
   ],
   "source": [
    "all_chunks = []\n",
    "\n",
    "for doc in documents:   # documents has 2 pages\n",
    "    chunks = split_document(doc)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(f\"Total chunks from all pages: {len(all_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7ee9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_chunks = []\n",
    "for chunk in all_chunks:\n",
    "    text = chunk.page_content\n",
    "    # Remove birthdates or patterns like '10th April 1992'\n",
    "    import re\n",
    "    text = re.sub(r'\\d{1,2}(st|nd|rd|th)?\\s[A-Z][a-z]+\\s\\d{4}', '[REDACTED]', text)\n",
    "    # Create a new document chunk with cleaned text\n",
    "    new_chunk = chunk\n",
    "    new_chunk.page_content = text\n",
    "    cleaned_chunks.append(new_chunk)\n",
    "\n",
    "all_chunks = cleaned_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "486900de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any,Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10cdcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Loaded model: {self.model_name}\")\n",
    "            print(f\"Model device: {self.model.device}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise e\n",
    "    def generate_embedding(self, text: str) -> np.ndarray:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        embedding = self.model.encode(text,show_progress_bar=True)\n",
    "        print(f\"Generated embedding of shape: {embedding.shape}\")\n",
    "        return embedding\n",
    "    def get_embeddings_dimension(self) -> int:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adaa5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: all-MiniLM-L6-v2\n",
      "Model device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager\n",
    "embedding_manager.get_embeddings_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5fb6b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized: pdf_documents\n",
      "Existing documents in collection: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1e504a35160>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.initialize_store()\n",
    "\n",
    "    def initialize_store(self):\n",
    "        try:\n",
    "            # Make sure the persistence directory exists\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "\n",
    "            # Initialize Chroma persistent client\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create the collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"Description\": \"PDF document embeddings for RAG\"}\n",
    "            )\n",
    "\n",
    "            # Print confirmation\n",
    "            print(f\"Vector store initialized: {self.collection.name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise e\n",
    "    def add_documents(self,documents:list[Any],embeddings:np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        for i, (doc,embedding) in enumerate(zip(documents,embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata[\"doc_index\"] = i\n",
    "            metadata[\"content_length\"] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            documents_text.append(doc.page_content)\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store.\")\n",
    "            print(f\"Total documents in collection now: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise e\n",
    "        \n",
    "vectorstore=VectorStore()\n",
    "vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "30da2eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2025-12-22T09:34:00+00:00', 'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='- Campaign optimization and ROI-focused strategies.\\nGraphics & Animation:\\n-  2D  animation,  motion  graphics,  logo  animation,  video  editing  (After  Effects,\\nPhotoshop, Illustrator, Moho).\\n- Design expertise: PDFs, PPTs, banners, marketing collaterals.\\nProjects & Achievements:\\n- Developed multiple ML/DL solutions and enterprise automation systems.\\n- Built full-stack web applications, Chrome extensions, and React/Next.js projects.\\n- Created Android apps including Object Detection, Tetromino Game, Weather App, and\\nATS app.\\n- Developed 4 Unity-based games and multiple games using pure JavaScript animation\\nwith custom sprites.\\n- In high school, made amendments in De Morgan’s Laws and received a medal via Intel\\n/ Government of Pakistan.\\nProfessional Attributes:\\n- Strong team player and collaborator.\\n- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'PyPDF', 'creationdate': '2025-12-22T09:34:00+00:00', 'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.\\n- Strategically skilled in digital marketing and campaign optimization.\\n-  Experienced  educator  with  a  proven  track  record  of  7  years  teaching  in  schools,\\ncolleges, and academies.\\nHobbies & Interests:\\n- Playing cricket, coding, and exploring AI advancements.\\n- Reading books and solving complex problems.\\n- Passionate about projects in advanced AI systems, driverless cars, and autonomous\\ntechnologies.\\n- LinkedIn: https://www.linkedin.com/in/muhammad-zubair-6230a1285/\\n- GitHub: https://github.com/Muhammad-Zubair796\\n- Active Phone: 03401071629')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a43471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['About Me\\nMy name is Muhammad Zubair, born on [REDACTED], from Islamabad, Pakistan. I am\\na highly skilled professional with a diverse educational and technical background — CA,\\nBS in Physics, and extensive expertise in Machine Learning, Artificial Intelligence, Web\\n&  Mobile  Development,  Game  Development,  Digital  Marketing,  Creative  Design,  and\\nAnimation software such as Moho.\\nWith over 6 years of professional experience on platforms like Fiverr and Upwork, I have\\nsuccessfully  completed  50+  projects  for  diverse  clients,  consistently  maintaining  a\\n5-star  rating.  My  work  spans  ML/DL  model  development,  full-stack  web  development,\\nmobile  apps,  games,  cloud  deployment,  digital  marketing,  SEO/SEM,  and  creative\\ndesign,  demonstrating  versatility  and  a  commitment  to  delivering  high-quality\\nsolutions. Additionally, I have over 7 years of teaching experience in various schools,',\n",
       " 'design,  demonstrating  versatility  and  a  commitment  to  delivering  high-quality\\nsolutions. Additionally, I have over 7 years of teaching experience in various schools,\\ncolleges, and academies, sharing my expertise and mentoring students in technical and\\nprofessional subjects.\\nTechnical Skills & Expertise\\nMachine Learning & AI:\\n- ML/DL models including ANN, RNN, CNN, NLP.\\n-  Developed  practical  solutions:  flower  classification,  customer  churn  prediction,\\nsentiment analysis, bank fraud detection, ATS (CV-job matching) system.\\n- Built enterprise solutions like employee onboarding systems for HR departments.\\n- Experience with YOLO object detection, RAG, OpenCV, FastAPI, Flask, and deploying\\nmodels to Azure Cloud.\\n-  Familiar  with  CI/CD,  Dockerization,  containerization,  and  software  engineering  best\\npractices.\\nProgramming & Web/Mobile Development:\\n- Languages & frameworks: Python, JavaScript, Node.js, React, HTML, CSS, TypeScript,\\nUnity, Kotlin (currently learning).',\n",
       " 'practices.\\nProgramming & Web/Mobile Development:\\n- Languages & frameworks: Python, JavaScript, Node.js, React, HTML, CSS, TypeScript,\\nUnity, Kotlin (currently learning).\\n-  Android  development:  Extensive  experience  with  Android  Studio,  having  created\\nmultiple  Android  applications  including  Object  Detection  app,  Tetromino  Game,\\nWeather App, and Application Tracking System App.\\n- Game development: Create sprites and animate them using pure JavaScript without\\nframeworks, and also develop games in Unity. Built 4 interactive games.\\n- Web development: Full-stack projects, including business cards, portfolio sites, React\\napps, Next.js apps, Chrome extensions.\\n- Databases: MySQL, SQL queries, data-driven applications.\\n- Prompt engineering and AI solution prototyping.\\nDigital Marketing:\\n- SEO, SEM, Google Ads, Meta Ads, local SEO strategies.\\n- WordPress / WooCommerce development.',\n",
       " '- Campaign optimization and ROI-focused strategies.\\nGraphics & Animation:\\n-  2D  animation,  motion  graphics,  logo  animation,  video  editing  (After  Effects,\\nPhotoshop, Illustrator, Moho).\\n- Design expertise: PDFs, PPTs, banners, marketing collaterals.\\nProjects & Achievements:\\n- Developed multiple ML/DL solutions and enterprise automation systems.\\n- Built full-stack web applications, Chrome extensions, and React/Next.js projects.\\n- Created Android apps including Object Detection, Tetromino Game, Weather App, and\\nATS app.\\n- Developed 4 Unity-based games and multiple games using pure JavaScript animation\\nwith custom sprites.\\n- In high school, made amendments in De Morgan’s Laws and received a medal via Intel\\n/ Government of Pakistan.\\nProfessional Attributes:\\n- Strong team player and collaborator.\\n- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.',\n",
       " '- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.\\n- Strategically skilled in digital marketing and campaign optimization.\\n-  Experienced  educator  with  a  proven  track  record  of  7  years  teaching  in  schools,\\ncolleges, and academies.\\nHobbies & Interests:\\n- Playing cricket, coding, and exploring AI advancements.\\n- Reading books and solving complex problems.\\n- Passionate about projects in advanced AI systems, driverless cars, and autonomous\\ntechnologies.\\n- LinkedIn: https://www.linkedin.com/in/muhammad-zubair-6230a1285/\\n- GitHub: https://github.com/Muhammad-Zubair796\\n- Active Phone: 03401071629']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [chunk.page_content for chunk in all_chunks]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "241aac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embedding of shape: (5, 384)\n",
      "Adding 5 documents to vector store...\n",
      "Successfully added 5 documents to vector store.\n",
      "Total documents in collection now: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_manager.generate_embedding(texts)\n",
    "vectorstore.add_documents(all_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75acf0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "class RAGRetriever:\n",
    "    def __init__(self, vector_store: \"VectorStore\", embedding_manager: \"EmbeddingManager\", top_k: int = 5):\n",
    "        \"\"\"\n",
    "        Initialize the RAG retriever.\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Your vector store instance containing document embeddings.\n",
    "            embedding_manager: The embedding manager (SentenceTransformer).\n",
    "            top_k: Default number of documents to retrieve per query.\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def retrieve(self, query: str, score_threshold: float = 0.0, top_k: int = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve top_k documents based on similarity to the query.\n",
    "        \n",
    "        Args:\n",
    "            query: The query string.\n",
    "            score_threshold: Minimum similarity score to include a document.\n",
    "            top_k: Number of documents to retrieve for this query (optional, defaults to self.top_k).\n",
    "        \n",
    "        Returns:\n",
    "            List of dictionaries containing document info and similarity scores.\n",
    "        \"\"\"\n",
    "        top_k = top_k or self.top_k\n",
    "        print(f\"Retrieving top {top_k} documents for query: '{query}'\")\n",
    "\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.embedding_manager.generate_embedding([query])[0]\n",
    "\n",
    "        try:\n",
    "            # Query the vector store\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k,\n",
    "                include=['documents', 'metadatas', 'distances']\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "\n",
    "                for i, (document, metadata, distance) in enumerate(zip(documents, metadatas, distances)):\n",
    "                    # Normalize distance to similarity score (0..1)\n",
    "                    similarity_score = 1 / (1 + distance)\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            \"id\": metadata.get(\"doc_index\", i),\n",
    "                            \"content\": document,\n",
    "                            \"metadata\": metadata,\n",
    "                            \"similarity_score\": similarity_score,\n",
    "                            \"distance\": distance,\n",
    "                            \"rank\": i + 1\n",
    "                        })\n",
    "\n",
    "                        # Debug print: show snippet\n",
    "                        print(f\"Doc {i+1}, similarity={similarity_score:.3f}, snippet: {document[:75]}\")\n",
    "\n",
    "            if not retrieved_docs:\n",
    "                print(\"No documents above threshold.\")\n",
    "\n",
    "            return retrieved_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb4ad0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 5 documents for query: 'What is my name?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embedding of shape: (1, 384)\n",
      "Doc 1, similarity=0.404, snippet: About Me\n",
      "My name is Muhammad Zubair, born on 10th April 1992, from Islamaba\n",
      "Doc 2, similarity=0.404, snippet: About Me\n",
      "My name is Muhammad Zubair, born on 10th April 1992, from Islamaba\n",
      "Doc 3, similarity=0.395, snippet: About Me\n",
      "My name is Muhammad Zubair, born on [REDACTED], from Islamabad, Pa\n",
      "Doc 4, similarity=0.365, snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continu\n",
      "Doc 5, similarity=0.365, snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continu\n",
      "\n",
      "Retrieved 5 documents:\n",
      "Rank 1, Score: 0.404, Content snippet: About Me\n",
      "My name is Muhammad Zubair, born on 10th April 1992, from Islamabad, Pakistan. I am\n",
      "a highl\n",
      "Rank 2, Score: 0.404, Content snippet: About Me\n",
      "My name is Muhammad Zubair, born on 10th April 1992, from Islamabad, Pakistan. I am\n",
      "a highl\n",
      "Rank 3, Score: 0.395, Content snippet: About Me\n",
      "My name is Muhammad Zubair, born on [REDACTED], from Islamabad, Pakistan. I am\n",
      "a highly ski\n",
      "Rank 4, Score: 0.365, Content snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continuously  learning  emerging\n",
      "Rank 5, Score: 0.365, Content snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continuously  learning  emerging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "rag_retriever = RAGRetriever(vectorstore, embedding_manager)\n",
    "\n",
    "# Test query (replace with text from your PDF)\n",
    "results = rag_retriever.retrieve(\"What is my name?\")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results)} documents:\")\n",
    "for doc in results:\n",
    "    print(f\"Rank {doc['rank']}, Score: {doc['similarity_score']:.3f}, Content snippet: {doc['content'][:100]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e906db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model=\"llama-3.1-8b-instant\",   # Replace with your desired Groq model\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "# Improved RAG function\n",
    "def rag_simple(query: str, retriever, llm, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve top_k documents from the retriever, create a context,\n",
    "    and ask the LLM to answer the query based on that context.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    results = retriever.retrieve(query, top_k=top_k)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "\n",
    "    # Prepare context from retrieved documents\n",
    "    context = \"\\n\\n\".join([f\"- {doc['content']}\" for doc in results])\n",
    "\n",
    "    # Build system + human prompt for better guidance\n",
    "    messages = [\n",
    "        (\"system\", \"You are a precise and helpful assistant. Answer questions based on the provided context only. Do not make up information.\"),\n",
    "        (\"human\", f\"Use the following context to answer the question:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\")\n",
    "    ]\n",
    "\n",
    "    # Invoke the LLM\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f4d7a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 3 documents for query: 'github'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embedding of shape: (1, 384)\n",
      "Doc 1, similarity=0.396, snippet: practices.\n",
      "Programming & Web/Mobile Development:\n",
      "- Languages & frameworks: \n",
      "Doc 2, similarity=0.396, snippet: practices.\n",
      "Programming & Web/Mobile Development:\n",
      "- Languages & frameworks: \n",
      "Doc 3, similarity=0.396, snippet: practices.\n",
      "Programming & Web/Mobile Development:\n",
      "- Languages & frameworks: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no mention of GitHub in the provided context.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"github\", rag_retriever, llm)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f392d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_advanced(query: str, retriever, llm, top_k: int = 5, min_score: float = 0.2, return_context: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Advanced RAG function:\n",
    "    - Retrieves top-k relevant documents from the retriever\n",
    "    - Constructs context for the LLM\n",
    "    - Returns structured output with answer, sources, confidence, and optional context\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    results = retriever.retrieve(query)\n",
    "    if not results:\n",
    "        return {\n",
    "            \"answer\": \"No relevant context found to answer the question.\",\n",
    "            \"sources\": [],\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": \"\" if return_context else None\n",
    "        }\n",
    "\n",
    "    # Filter by min_score\n",
    "    results = [doc for doc in results if doc[\"similarity_score\"] >= min_score]\n",
    "    if not results:\n",
    "        return {\n",
    "            \"answer\": \"No relevant context found above the confidence threshold.\",\n",
    "            \"sources\": [],\n",
    "            \"confidence\": 0.0,\n",
    "            \"context\": \"\" if return_context else None\n",
    "        }\n",
    "\n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([f\"- {doc['content']}\" for doc in results])\n",
    "    sources = [{\n",
    "        \"source\": doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        \"page\": doc['metadata'].get('page', 'unknown'),\n",
    "        \"score\": doc['similarity_score'],\n",
    "        \"preview\": doc['content'][:1000] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max(doc['similarity_score'] for doc in results)\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = (\n",
    "        \"You are a precise and helpful assistant. Answer strictly based on the context below. \"\n",
    "        \"Do not make up information. Keep the answer concise and relevant.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    # Invoke LLM\n",
    "    response = llm.invoke([prompt])\n",
    "    answer = response.content.strip()\n",
    "\n",
    "    # Build output\n",
    "    output = {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": sources,\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output[\"context\"] = context\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61e17515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top 5 documents for query: 'does he plays cricket'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embedding of shape: (1, 384)\n",
      "Doc 1, similarity=0.412, snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continu\n",
      "Doc 2, similarity=0.412, snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continu\n",
      "Doc 3, similarity=0.412, snippet: - Analytical and critical thinker, solving problems efficiently.\n",
      "-  Continu\n",
      "Doc 4, similarity=0.370, snippet: - Campaign optimization and ROI-focused strategies.\n",
      "Graphics & Animation:\n",
      "-\n",
      "Doc 5, similarity=0.370, snippet: - Campaign optimization and ROI-focused strategies.\n",
      "Graphics & Animation:\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Yes, he plays cricket.', 'sources': [{'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'page': 1, 'score': 0.41217047054880046, 'preview': '- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.\\n- Strategically skilled in digital marketing and campaign optimization.\\n-  Experienced  educator  with  a  proven  track  record  of  7  years  teaching  in  schools,\\ncolleges, and academies.\\nHobbies & Interests:\\n- Playing cricket, coding, and exploring AI advancements.\\n- Reading books and solving complex problems.\\n- Passionate about projects in advanced AI systems, driverless cars, and autonomous\\ntechnologies.\\n- LinkedIn: https://www.linkedin.com/in/muhammad-zubair-6230a1285/\\n- GitHub: https://github.com/Muhammad-Zubair796\\n- Active Phone: 03401071629...'}, {'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'page': 1, 'score': 0.41217047054880046, 'preview': '- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.\\n- Strategically skilled in digital marketing and campaign optimization.\\n-  Experienced  educator  with  a  proven  track  record  of  7  years  teaching  in  schools,\\ncolleges, and academies.\\nHobbies & Interests:\\n- Playing cricket, coding, and exploring AI advancements.\\n- Reading books and solving complex problems.\\n- Passionate about projects in advanced AI systems, driverless cars, and autonomous\\ntechnologies.\\n- LinkedIn: https://www.linkedin.com/in/muhammad-zubair-6230a1285/\\n- GitHub: https://github.com/Muhammad-Zubair796\\n- Active Phone: 03401071629...'}, {'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'page': 1, 'score': 0.41217047054880046, 'preview': '- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems.\\n- Strategically skilled in digital marketing and campaign optimization.\\n-  Experienced  educator  with  a  proven  track  record  of  7  years  teaching  in  schools,\\ncolleges, and academies.\\nHobbies & Interests:\\n- Playing cricket, coding, and exploring AI advancements.\\n- Reading books and solving complex problems.\\n- Passionate about projects in advanced AI systems, driverless cars, and autonomous\\ntechnologies.\\n- LinkedIn: https://www.linkedin.com/in/muhammad-zubair-6230a1285/\\n- GitHub: https://github.com/Muhammad-Zubair796\\n- Active Phone: 03401071629...'}, {'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'page': 1, 'score': 0.3701009899219204, 'preview': '- Campaign optimization and ROI-focused strategies.\\nGraphics & Animation:\\n-  2D  animation,  motion  graphics,  logo  animation,  video  editing  (After  Effects,\\nPhotoshop, Illustrator, Moho).\\n- Design expertise: PDFs, PPTs, banners, marketing collaterals.\\nProjects & Achievements:\\n- Developed multiple ML/DL solutions and enterprise automation systems.\\n- Built full-stack web applications, Chrome extensions, and React/Next.js projects.\\n- Created Android apps including Object Detection, Tetromino Game, Weather App, and\\nATS app.\\n- Developed 4 Unity-based games and multiple games using pure JavaScript animation\\nwith custom sprites.\\n- In high school, made amendments in De Morgan’s Laws and received a medal via Intel\\n/ Government of Pakistan.\\nProfessional Attributes:\\n- Strong team player and collaborator.\\n- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems....'}, {'source': 'D:\\\\New folder (2)\\\\DS\\\\RAG\\\\ZuGraFix\\\\data\\\\text_files\\\\aboutme.pdf', 'page': 1, 'score': 0.3701009899219204, 'preview': '- Campaign optimization and ROI-focused strategies.\\nGraphics & Animation:\\n-  2D  animation,  motion  graphics,  logo  animation,  video  editing  (After  Effects,\\nPhotoshop, Illustrator, Moho).\\n- Design expertise: PDFs, PPTs, banners, marketing collaterals.\\nProjects & Achievements:\\n- Developed multiple ML/DL solutions and enterprise automation systems.\\n- Built full-stack web applications, Chrome extensions, and React/Next.js projects.\\n- Created Android apps including Object Detection, Tetromino Game, Weather App, and\\nATS app.\\n- Developed 4 Unity-based games and multiple games using pure JavaScript animation\\nwith custom sprites.\\n- In high school, made amendments in De Morgan’s Laws and received a medal via Intel\\n/ Government of Pakistan.\\nProfessional Attributes:\\n- Strong team player and collaborator.\\n- Analytical and critical thinker, solving problems efficiently.\\n-  Continuously  learning  emerging  technologies,  especially  in  AI  and  autonomous\\nsystems....'}], 'confidence': 0.41217047054880046}\n"
     ]
    }
   ],
   "source": [
    "answer = rag_advanced(\"does he plays cricket\", rag_retriever, llm, top_k=5)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84007e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZuGraFix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
